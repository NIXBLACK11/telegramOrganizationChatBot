{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA-WfESwhggy",
        "outputId": "db2933f2-543a-43e5-a392-0bba7f65d299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: laser_encoders in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: sacremoses==0.1.0 in /usr/local/lib/python3.10/dist-packages (from laser_encoders) (0.1.0)\n",
            "Requirement already satisfied: unicategories>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from laser_encoders) (0.1.2)\n",
            "Requirement already satisfied: sentencepiece>=0.1.99 in /usr/local/lib/python3.10/dist-packages (from laser_encoders) (0.1.99)\n",
            "Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from laser_encoders) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from laser_encoders) (2.1.0+cu121)\n",
            "Requirement already satisfied: fairseq>=0.12.2 in /usr/local/lib/python3.10/dist-packages (from laser_encoders) (0.12.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.1.0->laser_encoders) (2023.6.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.1.0->laser_encoders) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.1.0->laser_encoders) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.1.0->laser_encoders) (4.66.1)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq>=0.12.2->laser_encoders) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq>=0.12.2->laser_encoders) (3.0.8)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from fairseq>=0.12.2->laser_encoders) (1.0.7)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.10/dist-packages (from fairseq>=0.12.2->laser_encoders) (2.0.6)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from fairseq>=0.12.2->laser_encoders) (2.4.0)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.10/dist-packages (from fairseq>=0.12.2->laser_encoders) (2.9.2)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq>=0.12.2->laser_encoders) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->laser_encoders) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->laser_encoders) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->laser_encoders) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->laser_encoders) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->laser_encoders) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->laser_encoders) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->laser_encoders) (2.1.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from unicategories>=0.1.2->laser_encoders) (1.4.4)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq>=0.12.2->laser_encoders) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq>=0.12.2->laser_encoders) (6.0.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq>=0.12.2->laser_encoders) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq>=0.12.2->laser_encoders) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq>=0.12.2->laser_encoders) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq>=0.12.2->laser_encoders) (4.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq>=0.12.2->laser_encoders) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->laser_encoders) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->laser_encoders) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install laser_encoders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_data = {\n",
        "  \"intents\": [\n",
        "    {\n",
        "      \"tag\": \"greeting\",\n",
        "      \"patterns\": [\n",
        "        \"Hi\",\n",
        "        \"Hey\",\n",
        "        \"How are you\",\n",
        "        \"Is anyone there?\",\n",
        "        \"Hello\",\n",
        "        \"Good day\",\n",
        "        \"What is your name?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Hi there, how can Nimble help?\\nYou can ask me about bank information like\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"quit\",\n",
        "      \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\n",
        "      \"responses\": [\n",
        "        \"See you later, thanks for visiting\",\n",
        "        \"Have a nice day\",\n",
        "        \"Bye! Come back again soon.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"thanks\",\n",
        "      \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Thank's a lot!\"],\n",
        "      \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"balance_enquiry\",\n",
        "      \"patterns\": [\"can you tell me my account balance\", \"what is my account balance\", \"what is my account balance\", \"what is my account status\"],\n",
        "      \"responses\":[\"balance_enquiry\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"balance_graph\",\n",
        "      \"patterns\": [\"can you tell me the graph of balance\", \"show me the balance graph\", \"balance graph\", \"show me my account balance graph\"],\n",
        "      \"responses\":[\"balance_graph\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"latest_updates\",\n",
        "      \"patterns\": [\"what are the latest updates about the bank\", \"what are the updates in policy\", \"what is the latest news regarding the bank\"],\n",
        "      \"responses\":[\"latest_updates\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"interest_rates\",\n",
        "      \"patterns\": [\"what are the interest rates provided by your bank\", \"tell me about the interest rates of your bank\", \"interest rates?\", \"what are the changes in the interest\"],\n",
        "      \"responses\":[\"interest_rates\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"UnderstandQuery\",\n",
        "      \"patterns\": [\"Do you understand what I am saying\",\"Do you understand me\",\"Do you know what I am saying\",\"Do you get me\",\"Comprendo\",\"Know what I mean\"],\n",
        "      \"responses\": [\"Well I would not be a very clever AI if I did not would I?\",\"I read you loud and clear!\",\"I do in deed!\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"Shutup\",\n",
        "      \"patterns\": [\"Be quiet\",\"Shut up\",\"Stop talking\",\"Enough talking\",\"Please be quiet\",\"Quiet\",\"Shhh\"],\n",
        "      \"responses\": [\"I am sorry to disturb you\",\"Fine, sorry to disturb you\",\"OK, sorry to disturb you\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"Swearing\",\n",
        "      \"patterns\": [\"fuck off\",\"fuck\",\"twat\",\"shit\"],\n",
        "      \"responses\": [\"Please do not swear\",\"How rude\",\"That is not very nice\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"Clever\",\n",
        "      \"patterns\": [\"You are very clever\",\"You are a very clever girl\",\"You are very intelligent\", \"You are a very intelligent girl\",\"You are a genious\",\"Genious\"],\n",
        "      \"responses\": [\"Thank you, I was trained that way\",\"I was trained well\",\"Thanks, I was trained that way\"]\n",
        "    },\n",
        "    # {\n",
        "    #   \"tag\": \"Jokes\",\n",
        "    #   \"patterns\": [\"Tell me a joke\", \"Do you know any jokes\",\"How about a joke\",\"Give me a joke\",\"Make me laugh\",\"I need cheering up\"],\n",
        "    #   \"responses\": [\n",
        "    #                     \"I met a Dutch girl with inflatable shoes last week, phoned her up to arrange a date but unfortunately she'd popped her clogs.  \",\n",
        "    #                     \"So I said 'Do you want a game of Darts?' He said, 'OK then', I said nearest to bull starts'. He said, 'Baa', I said, 'Moo', he said, You're closest'.  \",\n",
        "    #                     \"The other day I sent my girlfriend a huge pile of snow. I rang her up; I said 'Did you get my drift?'  \",\n",
        "    #                     \"So I went down the local supermarket, I said, 'I want to make a complaint, this vinegar's got lumps in it', he said, 'Those are pickled onions'.  \"\n",
        "    #                 ]\n",
        "    # },\n",
        "    {\n",
        "      \"tag\": \"TimeQuery\",\n",
        "      \"patterns\": [\"What is the time?\",\"What's the time?\",\"Do you know what time it is?\",\"Do you know the time?\",\"Can you tell me the time?\",\"Tell me what time it is?\",\"Time\"],\n",
        "      \"responses\": [\"TimeQuery\"]\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "w8wAXf6amOA2"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = [\n",
        "    \"greeting\",\n",
        "    \"quit\",\n",
        "    \"thanks\",\n",
        "    \"balance_enquiry\",\n",
        "    \"balance_graph\",\n",
        "    \"latest_updates\",\n",
        "    \"interest_rates\",\n",
        "    \"UnderstandQuery\",\n",
        "    \"Shutup\",\n",
        "    \"Swearing\",\n",
        "    \"Clever\",\n",
        "    \"Jokes\",\n",
        "    \"TimeQuery\"\n",
        "]"
      ],
      "metadata": {
        "id": "I6ixqK8KmYwn"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from laser_encoders import LaserEncoderPipeline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Reshape, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "XffrfoklqopK"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract intent tags\n",
        "intent_tags = [intent[\"tag\"] for intent in json_data[\"intents\"]]"
      ],
      "metadata": {
        "id": "7Lbv3dHHqrkc"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the intent tags to integer labels\n",
        "encoded_tags = label_encoder.fit_transform(intent_tags)"
      ],
      "metadata": {
        "id": "I16zAj6mq30N"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data using tuples (pattern, encoded_tag)\n",
        "data = [(pattern, encoded_tag) for intent in json_data[\"intents\"] for pattern, encoded_tag in zip(intent[\"patterns\"], encoded_tags)]\n",
        "\n",
        "response = intent_tags  # Update response list\n",
        "\n",
        "print(encoded_tags)\n",
        "# print()\n",
        "\n",
        "counter = Counter(encoded_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxi_2NtmrU8u",
        "outputId": "e17c9de3-322f-4400-dd1d-7a0dd2a65521"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 7 10 11  5  6  9  8  4  1  2  0  3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Class distribution:\")\n",
        "for cls, count in counter.items():\n",
        "    print(f\"Class {cls}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLWawNjarb2Q",
        "outputId": "541d7cb8-04b5-4618-c712-25cf5d580b10"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution:\n",
            "Class 7: 1\n",
            "Class 10: 1\n",
            "Class 11: 1\n",
            "Class 5: 1\n",
            "Class 6: 1\n",
            "Class 9: 1\n",
            "Class 8: 1\n",
            "Class 4: 1\n",
            "Class 1: 1\n",
            "Class 2: 1\n",
            "Class 0: 1\n",
            "Class 3: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the LaserEncoder\n",
        "encoder = LaserEncoderPipeline(lang=\"eng_Latn\")\n",
        "\n",
        "# Initialize empty arrays to store embeddings\n",
        "X_embeddings = []"
      ],
      "metadata": {
        "id": "oEZ3q_jGrgyL"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode sentences line-wise using tqdm for progress visualization\n",
        "print(\"Encoding sentences:\")\n",
        "for sentence in tqdm([row[0] for row in data]):\n",
        "    embeddings = encoder.encode_sentences([sentence])[0]\n",
        "    X_embeddings.append(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YTx9B3trkxe",
        "outputId": "d17fb750-1f51-4a47-d2e3-455271133b04"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding sentences:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 59/59 [00:02<00:00, 20.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert list to numpy array\n",
        "X_embeddings = np.array(X_embeddings)\n",
        "\n",
        "# Convert tags to a NumPy array\n",
        "y_train = np.array([row[1] for row in data])"
      ],
      "metadata": {
        "id": "8-nqf1ST0SIC"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network model with RNN\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(1024,), activation='tanh'))\n",
        "model.add(Reshape((1, 256)))\n",
        "model.add(SimpleRNN(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Adding dropout for regularization\n",
        "model.add(Dense(len(set(encoded_tags)), activation='softmax'))\n",
        "\n",
        "# Use a learning rate scheduler\n",
        "def lr_schedule(epoch):\n",
        "    return 0.0001 * 0.9 ** epoch\n",
        "\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary to check the architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz7QDOyQrrug",
        "outputId": "734a4615-a487-485c-f544-0cdfe0edba2b"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 256)               262400    \n",
            "                                                                 \n",
            " reshape_8 (Reshape)         (None, 1, 256)            0         \n",
            "                                                                 \n",
            " simple_rnn_8 (SimpleRNN)    (None, 128)               49280     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 12)                780       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320716 (1.22 MB)\n",
            "Trainable params: 320716 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model without validation split\n",
        "model.fit(X_embeddings, y_train, epochs=30, batch_size=32, callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnlPe9Qe0bFL",
        "outputId": "cc8c6d38-73dc-4eef-f79c-08932db43d63"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "2/2 [==============================] - 2s 15ms/step - loss: 2.4825 - accuracy: 0.0847 - lr: 1.0000e-04\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4785 - accuracy: 0.1525 - lr: 9.0000e-05\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.4747 - accuracy: 0.1695 - lr: 8.1000e-05\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.4754 - accuracy: 0.2034 - lr: 7.2900e-05\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4734 - accuracy: 0.2712 - lr: 6.5610e-05\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4696 - accuracy: 0.2542 - lr: 5.9049e-05\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4646 - accuracy: 0.2712 - lr: 5.3144e-05\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4657 - accuracy: 0.3051 - lr: 4.7830e-05\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4658 - accuracy: 0.3051 - lr: 4.3047e-05\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4664 - accuracy: 0.2712 - lr: 3.8742e-05\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4649 - accuracy: 0.2034 - lr: 3.4868e-05\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.4629 - accuracy: 0.2542 - lr: 3.1381e-05\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4567 - accuracy: 0.2712 - lr: 2.8243e-05\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4614 - accuracy: 0.3051 - lr: 2.5419e-05\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4579 - accuracy: 0.3220 - lr: 2.2877e-05\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.4614 - accuracy: 0.2373 - lr: 2.0589e-05\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4581 - accuracy: 0.2712 - lr: 1.8530e-05\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4549 - accuracy: 0.3220 - lr: 1.6677e-05\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4602 - accuracy: 0.2034 - lr: 1.5009e-05\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.4579 - accuracy: 0.3051 - lr: 1.3509e-05\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.4580 - accuracy: 0.2542 - lr: 1.2158e-05\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.4581 - accuracy: 0.3051 - lr: 1.0942e-05\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4490 - accuracy: 0.3390 - lr: 9.8477e-06\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4564 - accuracy: 0.2712 - lr: 8.8629e-06\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4614 - accuracy: 0.3051 - lr: 7.9766e-06\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4570 - accuracy: 0.2542 - lr: 7.1790e-06\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.4524 - accuracy: 0.3220 - lr: 6.4611e-06\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.4517 - accuracy: 0.3390 - lr: 5.8150e-06\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4526 - accuracy: 0.1864 - lr: 5.2335e-06\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4508 - accuracy: 0.2881 - lr: 4.7101e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79e9e677e1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts_to_predict_how_are_you = {\n",
        "    'hindi': \"क्या हाल है आपका\",\n",
        "    'portuguese': \"Como você está\",\n",
        "    'romanian': \"Ce mai faci\",\n",
        "    'slovenian': \"Kako se počutiš\",\n",
        "    'chinese': \"你好吗\",\n",
        "    'french': \"Comment ça va\",\n",
        "    'dutch': \"Hoe gaat het met je\",\n",
        "    'russian': \"Как вы\",\n",
        "    'italian': \"Come stai\",\n",
        "    'bosnian': \"Kako si\"\n",
        "}"
      ],
      "metadata": {
        "id": "eYzfxp97uEri"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the dictionary and extract values\n",
        "for language, user_text in texts_to_predict_how_are_you.items():\n",
        "    print(f\"{language.capitalize()}: {user_text}\")\n",
        "\n",
        "    # Encode the user text\n",
        "    user_text_embedding = encoder.encode_sentences([user_text])[0]\n",
        "    user_text_embedding = np.reshape(user_text_embedding, (1, -1))\n",
        "\n",
        "    # Predict intent using the trained model\n",
        "    predicted_intent_index = np.argmax(model.predict(user_text_embedding))\n",
        "    predicted_intent_tag = response[predicted_intent_index]\n",
        "\n",
        "    print(f\"Predicted Intent (Class Number): {predicted_intent_index}\")\n",
        "    print(f\"Predicted Intent (Tag Name): {predicted_intent_tag}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAZj8m3Vtlip",
        "outputId": "f3350cf3-1665-4343-daf4-1a4eaeb876bb"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hindi: क्या हाल है आपका\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Predicted Intent (Class Number): 7\n",
            "Predicted Intent (Tag Name): UnderstandQuery\n",
            "\n",
            "Portuguese: Como você está\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Predicted Intent (Class Number): 7\n",
            "Predicted Intent (Tag Name): UnderstandQuery\n",
            "\n",
            "Romanian: Ce mai faci\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicted Intent (Class Number): 11\n",
            "Predicted Intent (Tag Name): TimeQuery\n",
            "\n",
            "Slovenian: Kako se počutiš\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicted Intent (Class Number): 7\n",
            "Predicted Intent (Tag Name): UnderstandQuery\n",
            "\n",
            "Chinese: 你好吗\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicted Intent (Class Number): 11\n",
            "Predicted Intent (Tag Name): TimeQuery\n",
            "\n",
            "French: Comment ça va\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicted Intent (Class Number): 11\n",
            "Predicted Intent (Tag Name): TimeQuery\n",
            "\n",
            "Dutch: Hoe gaat het met je\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Predicted Intent (Class Number): 11\n",
            "Predicted Intent (Tag Name): TimeQuery\n",
            "\n",
            "Russian: Как вы\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Predicted Intent (Class Number): 11\n",
            "Predicted Intent (Tag Name): TimeQuery\n",
            "\n",
            "Italian: Come stai\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicted Intent (Class Number): 7\n",
            "Predicted Intent (Tag Name): UnderstandQuery\n",
            "\n",
            "Bosnian: Kako si\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicted Intent (Class Number): 11\n",
            "Predicted Intent (Tag Name): TimeQuery\n",
            "\n"
          ]
        }
      ]
    }
  ]
}